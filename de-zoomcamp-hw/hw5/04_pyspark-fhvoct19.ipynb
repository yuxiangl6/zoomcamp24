{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07de9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5bbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 18:25:25 WARN Utils: Your hostname, codespaces-373050 resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "24/03/03 18:25:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/03 18:25:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931021a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0186f-625b-441f-a971-48c2cb24fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date',F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date',F.to_date(df.dropOff_datetime)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a361f68-3e17-49d8-b73d-4f7cd7b3fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema = types.StructType([\n",
    "    types.StructField(\"dispatching_base_num\", types.StringType(), True),\n",
    "    types.StructField(\"pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"dropOff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"PULocationID\", types.StringType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.StringType(), True),\n",
    "    types.StructField(\"SR_Flag\", types.StringType(), True),\n",
    "    types.StructField(\"Affiliated_base_number\", types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744900f5-3e7d-428b-a1be-854f11cfb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(df_schema) \\\n",
    "        .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27d6492-4abf-465d-8021-085ad5536101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 18:25:43 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .repartition(6) \\\n",
    "    .write.parquet('data/fhvoct19', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9602a438-e36f-49d3-b882-323fc7dbbf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e526cce2-92c4-4720-b357-649f1080ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('fhv_oct19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c29c54-56c4-48b3-8305-f2829161b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15oct_count = spark.sql(\"\"\"\n",
    "SELECT COUNT(*) as rowcount\n",
    "FROM fhv_oct19\n",
    "WHERE TO_DATE(pickup_datetime)=\"2019-10-15\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a4c3ae-d561-4ff9-898f-3963c46ed89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|rowcount|\n",
      "+--------+\n",
      "|   62610|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_15oct_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad18333-8a9d-43e1-ba8c-abf8eb900eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_trip = spark.sql(\"\"\"\n",
    "SELECT (dropOff_datetime - pickup_datetime)*24 AS length_hrs\n",
    "FROM fhv_oct19\n",
    "ORDER BY length_hrs DESC\n",
    "LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ac2efc-2f6a-4380-9dce-4799aa8b900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          length_hrs|\n",
      "+--------------------+\n",
      "|INTERVAL '631152 ...|\n",
      "|INTERVAL '631152 ...|\n",
      "|INTERVAL '87672 1...|\n",
      "|INTERVAL '70128 0...|\n",
      "|INTERVAL '8794 00...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_long_trip.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb39865d-7839-43dd-8d7e-99eb0ceecd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('zones/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4b605e-fdee-4dba-984f-c7b3b15c5cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41be7a1-cd05-4452-a524-829b38727b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df.join(df_zones, df.PULocationID == df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e364b18-fae0-43a1-b89b-95f7c0a7d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbcb73ae-bc1b-4e23-9a61-2af4fcb0ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.createOrReplaceTempView('fhv_oct19_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4505c2e1-7531-4b52-b2b6-982a8352027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_leastPU = spark.sql(\"\"\"\n",
    "SELECT Zone, COUNT(*) as rowcount\n",
    "FROM fhv_oct19_result\n",
    "GROUP BY Zone\n",
    "ORDER BY rowcount ASC\n",
    "LIMIT 5    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df06346-8d37-454c-a60a-024f442a2edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                Zone|rowcount|\n",
      "+--------------------+--------+\n",
      "|         Jamaica Bay|       1|\n",
      "|Governor's Island...|       2|\n",
      "| Green-Wood Cemetery|       5|\n",
      "|       Broad Channel|       8|\n",
      "|     Highbridge Park|      14|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result_leastPU.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73a3f316-dc5a-455d-9a2c-849a2706a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e58fb5-f816-4fdf-8baf-73c13dada2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
